{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os, glob, re, pickle\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "import operator as op\n",
    "from cytoolz import compose\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import loompy as lp\n",
    "import anndata as ad\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyscenic.export import export2loom, add_scenic_metadata\n",
    "from pyscenic.utils import load_motifs\n",
    "from pyscenic.transform import df2regulons\n",
    "from pyscenic.aucell import aucell\n",
    "from pyscenic.binarization import binarize\n",
    "from pyscenic.rss import regulon_specificity_scores\n",
    "from pyscenic.plotting import plot_binarization, plot_rss\n",
    "\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "anndata     0.8.0\n",
      "scanpy      1.9.1\n",
      "-----\n",
      "PIL                         9.2.0\n",
      "asttokens                   NA\n",
      "attr                        22.1.0\n",
      "backcall                    0.2.0\n",
      "beta_ufunc                  NA\n",
      "binom_ufunc                 NA\n",
      "boltons                     NA\n",
      "bottleneck                  1.3.5\n",
      "cloudpickle                 2.2.0\n",
      "ctxcore                     0.2.0\n",
      "cycler                      0.10.0\n",
      "cython_runtime              NA\n",
      "cytoolz                     0.12.0\n",
      "dask                        2022.9.1\n",
      "dateutil                    2.8.2\n",
      "debugpy                     1.5.1\n",
      "decorator                   5.1.1\n",
      "entrypoints                 0.4\n",
      "executing                   0.8.3\n",
      "frozendict                  2.3.4\n",
      "fsspec                      2022.8.2\n",
      "h5py                        3.7.0\n",
      "ipykernel                   6.15.2\n",
      "jedi                        0.18.1\n",
      "jinja2                      3.1.2\n",
      "joblib                      1.2.0\n",
      "kiwisolver                  1.4.2\n",
      "llvmlite                    0.39.1\n",
      "loompy                      3.0.7\n",
      "markupsafe                  2.1.1\n",
      "matplotlib                  3.5.2\n",
      "mpl_toolkits                NA\n",
      "natsort                     8.2.0\n",
      "nbinom_ufunc                NA\n",
      "networkx                    2.8.6\n",
      "numba                       0.56.2\n",
      "numexpr                     2.8.3\n",
      "numpy                       1.22.4\n",
      "numpy_groupies              0.9.19\n",
      "packaging                   21.3\n",
      "pandas                      1.4.3\n",
      "parso                       0.8.3\n",
      "pexpect                     4.8.0\n",
      "pickleshare                 0.7.5\n",
      "pkg_resources               NA\n",
      "prompt_toolkit              3.0.20\n",
      "psutil                      5.9.0\n",
      "ptyprocess                  0.7.0\n",
      "pure_eval                   0.2.2\n",
      "pyarrow                     9.0.0\n",
      "pydev_ipython               NA\n",
      "pydevconsole                NA\n",
      "pydevd                      2.6.0\n",
      "pydevd_concurrency_analyser NA\n",
      "pydevd_file_utils           NA\n",
      "pydevd_plugins              NA\n",
      "pydevd_tracing              NA\n",
      "pygments                    2.11.2\n",
      "pyparsing                   3.0.9\n",
      "pyscenic                    0.12.0\n",
      "pytz                        2022.1\n",
      "scipy                       1.7.3\n",
      "seaborn                     0.11.2\n",
      "session_info                1.0.0\n",
      "six                         1.16.0\n",
      "sklearn                     1.1.2\n",
      "stack_data                  0.2.0\n",
      "statsmodels                 0.13.2\n",
      "tblib                       1.7.0\n",
      "threadpoolctl               3.1.0\n",
      "tlz                         0.12.0\n",
      "toolz                       0.12.0\n",
      "tornado                     6.2\n",
      "tqdm                        4.64.1\n",
      "traitlets                   5.1.1\n",
      "typing_extensions           NA\n",
      "wcwidth                     0.2.5\n",
      "yaml                        6.0\n",
      "zmq                         23.2.0\n",
      "-----\n",
      "IPython             8.4.0\n",
      "jupyter_client      7.3.5\n",
      "jupyter_core        4.10.0\n",
      "-----\n",
      "Python 3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]\n",
      "Linux-5.4.0-124-generic-x86_64-with-glibc2.31\n",
      "-----\n",
      "Session information updated at 2022-09-19 16:23\n"
     ]
    }
   ],
   "source": [
    "sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()\n",
    "sc.settings.set_figure_params(dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set maximum number of jobs for Scanpy.\n",
    "sc.settings.njobs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCES_FOLDERNAME = \"/home/shpc_100839/scRNA_BC_metastases/Data/integrate_sc_BC/tumor/h5ad/filter_NG/\"\n",
    "AUXILLIARIES_FOLDERNAME = \"/home/shpc_100839/software/SCENICdata/\"\n",
    "RESULTS_FOLDERNAME = \"/home/shpc_100839/scRNA_BC_metastases/Data/integrate_sc_BC/tumor/SCENIC/\"\n",
    "FIGURES_FOLDERNAME = \"/home/shpc_100839/scRNA_BC_metastases/Data/integrate_sc_BC/tumor/SCENIC/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.figdir = FIGURES_FOLDERNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://motifcollections.aertslab.org/v10nr_clust/logos/\"\n",
    "COLUMN_NAME_LOGO = \"MotifLogo\"\n",
    "COLUMN_NAME_MOTIF_ID = \"MotifID\"\n",
    "COLUMN_NAME_TARGETS = \"TargetGenes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savesvg(fname: str, fig, folder: str=FIGURES_FOLDERNAME) -> None:\n",
    "    \"\"\"\n",
    "    Save figure as vector-based SVG image format.\n",
    "    \"\"\"\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(folder, fname), format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_logos(df: pd.DataFrame, top_target_genes: int = 3, base_url: str = BASE_URL):\n",
    "    \"\"\"\n",
    "    :param df:\n",
    "    :param base_url:\n",
    "    \"\"\"\n",
    "    # Make sure the original dataframe is not altered.\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Add column with URLs to sequence logo.\n",
    "    def create_url(motif_id):\n",
    "        return '<img src=\"{}{}.png\" style=\"max-height:124px;\"></img>'.format(base_url, motif_id)\n",
    "    df[(\"Enrichment\", COLUMN_NAME_LOGO)] = list(map(create_url, df.index.get_level_values(COLUMN_NAME_MOTIF_ID)))\n",
    "    \n",
    "    # Truncate TargetGenes.\n",
    "    def truncate(col_val):\n",
    "        return sorted(col_val, key=op.itemgetter(1))[:top_target_genes]\n",
    "    df[(\"Enrichment\", COLUMN_NAME_TARGETS)] = list(map(truncate, df[(\"Enrichment\", COLUMN_NAME_TARGETS)]))\n",
    "    \n",
    "    MAX_COL_WIDTH = pd.get_option('display.max_colwidth')\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    display(HTML(df.head().to_html(escape=False)))\n",
    "    pd.set_option('display.max_colwidth', MAX_COL_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_TFS_FNAME = os.path.join(AUXILLIARIES_FOLDERNAME, 'allTFs_hg38.txt')\n",
    "RANKING_DBS_FNAMES = os.path.join(AUXILLIARIES_FOLDERNAME,'hg38_500bp_up_100bp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather')\n",
    "                                                        # hg38_10kbp_up_10kbp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather\n",
    "MOTIF_ANNOTATIONS_FNAME = os.path.join(AUXILLIARIES_FOLDERNAME, 'motifs-v10nr_clust-nr.hgnc-m0.001-o0.0.tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_ID = \"atac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_H5AD_FNAME = os.path.join(RESOURCES_FOLDERNAME, 'atac.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FILTER_LOOM_FNAME = os.path.join(RESULTS_FOLDERNAME, '{}.h5ad.filter.loom'.format(SAMPLE_ID))\n",
    "ADJACENCIES_FNAME = os.path.join(RESULTS_FOLDERNAME, '{}.adjacencies.tsv'.format(SAMPLE_ID))\n",
    "MOTIFS_FNAME = os.path.join(RESULTS_FOLDERNAME, '{}.motifs.csv'.format(SAMPLE_ID))\n",
    "REGULONS_DAT_FNAME = os.path.join(RESULTS_FOLDERNAME, '{}.regulons.dat'.format(SAMPLE_ID))\n",
    "AUCELL_MTX_FNAME = os.path.join(RESULTS_FOLDERNAME, '{}.auc.csv'.format(SAMPLE_ID))\n",
    "BIN_MTX_FNAME = os.path.join(RESULTS_FOLDERNAME, '{}.bin.csv'.format(SAMPLE_ID))\n",
    "THR_FNAME = os.path.join(RESULTS_FOLDERNAME, '{}.thresholds.csv'.format(SAMPLE_ID))\n",
    "ANNDATA_FNAME = os.path.join(RESULTS_FOLDERNAME, '{}.h5ad'.format(SAMPLE_ID))\n",
    "LOOM_FNAME = os.path.join(RESULTS_FOLDERNAME, '{}.loom'.format(SAMPLE_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 90 × 8872\n",
       "    obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'cell.id', 'singler.label', 'singler.celltype.compartment', 'paper.celltype.compartment', 'paper.celltype.major', 'paper.celltype.minor', 'paper.celltype.subset', 'primary.subtype', 'site', 'study', 'celltype.compartment', 'sample', 'cell.names', 'copykat.pred'\n",
       "    var: 'features'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad(EXP_H5AD_FNAME)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of counts (in the dataset units) per gene: 5.0  -  49037.0\n",
      "Number of cells in which each gene is detected: 5  -  90\n"
     ]
    }
   ],
   "source": [
    "nCountsPerGene = np.sum(adata.X, axis=0)\n",
    "nCellsPerGene = np.sum(adata.X>0, axis=0)\n",
    "print(\"Number of counts (in the dataset units) per gene:\", nCountsPerGene.min(), \" - \" ,nCountsPerGene.max())\n",
    "print(\"Number of cells in which each gene is detected:\", nCellsPerGene.min(), \" - \" ,nCellsPerGene.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic row and column attributes for the loom file:\n",
    "row_attrs = {\n",
    "    \"Gene\": np.array(adata.var_names) ,\n",
    "}\n",
    "col_attrs = {\n",
    "    \"CellID\": np.array(adata.obs_names) ,\n",
    "    \"nGene\": np.array( np.sum(adata.X.transpose()>0 , axis=0)).flatten() ,\n",
    "    \"nUMI\": np.array( np.sum(adata.X.transpose() , axis=0)).flatten() ,\n",
    "}\n",
    "lp.create( EXP_FILTER_LOOM_FNAME, adata.X.transpose(), row_attrs, col_attrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1 Network inference based on GRNBoost2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-09-19 17:36:13,416 - pyscenic.cli.pyscenic - INFO - Loading expression matrix.\n",
      "\n",
      "2022-09-19 17:36:13,517 - pyscenic.cli.pyscenic - INFO - Inferring regulatory networks.\n",
      "preparing dask client\n",
      "parsing input\n",
      "creating dask graph\n",
      "16 partitions\n",
      "computing dask graph\n",
      "not shutting down client, client was created externally\n",
      "finished\n",
      "2022-09-19 17:56:06,827 - distributed.worker - WARNING - Heartbeat to scheduler failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/worker.py\", line 1191, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/utils_comm.py\", line 383, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/utils_comm.py\", line 368, in retry\n",
      "    return await coro()\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/core.py\", line 1154, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/core.py\", line 919, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 241, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50944 remote=tcp://127.0.0.1:32957>: Stream is closed\n",
      "2022-09-19 17:56:06,965 - distributed.worker - WARNING - Heartbeat to scheduler failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/worker.py\", line 1191, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/utils_comm.py\", line 383, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/utils_comm.py\", line 368, in retry\n",
      "    return await coro()\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/core.py\", line 1154, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/core.py\", line 919, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 241, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50946 remote=tcp://127.0.0.1:32957>: Stream is closed\n",
      "2022-09-19 17:56:06,994 - distributed.worker - WARNING - Heartbeat to scheduler failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/worker.py\", line 1191, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/utils_comm.py\", line 383, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/utils_comm.py\", line 368, in retry\n",
      "    return await coro()\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/core.py\", line 1154, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/core.py\", line 919, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 241, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/shpc_100839/miniconda3/envs/pyscenic/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50922 remote=tcp://127.0.0.1:32957>: Stream is closed\n",
      "2022-09-19 17:56:10,146 - distributed.nanny - WARNING - Worker process still alive after 3.1999868774414066 seconds, killing\n",
      "2022-09-19 17:56:10,147 - distributed.nanny - WARNING - Worker process still alive after 3.1999978637695317 seconds, killing\n",
      "2022-09-19 17:56:10,147 - distributed.nanny - WARNING - Worker process still alive after 3.199996795654297 seconds, killing\n",
      "2022-09-19 17:56:10,158 - distributed.nanny - WARNING - Worker process still alive after 3.19999740600586 seconds, killing\n",
      "2022-09-19 17:56:10,186 - distributed.nanny - WARNING - Worker process still alive after 3.199997711181641 seconds, killing\n",
      "2022-09-19 17:56:10,187 - distributed.nanny - WARNING - Worker process still alive after 3.1999961853027346 seconds, killing\n",
      "2022-09-19 17:56:10,187 - distributed.nanny - WARNING - Worker process still alive after 3.199996490478516 seconds, killing\n",
      "2022-09-19 17:56:10,187 - distributed.nanny - WARNING - Worker process still alive after 3.1999963378906253 seconds, killing\n",
      "2022-09-19 17:56:10,253 - distributed.nanny - WARNING - Worker process still alive after 3.1999951171875 seconds, killing\n",
      "2022-09-19 17:56:10,254 - distributed.nanny - WARNING - Worker process still alive after 3.199997253417969 seconds, killing\n",
      "2022-09-19 17:56:10,254 - distributed.nanny - WARNING - Worker process still alive after 3.199996795654297 seconds, killing\n",
      "2022-09-19 17:56:10,254 - distributed.nanny - WARNING - Worker process still alive after 3.1999971008300783 seconds, killing\n",
      "2022-09-19 17:56:10,255 - distributed.nanny - WARNING - Worker process still alive after 3.19999740600586 seconds, killing\n",
      "2022-09-19 17:56:10,255 - distributed.nanny - WARNING - Worker process still alive after 3.199997253417969 seconds, killing\n",
      "2022-09-19 17:56:10,264 - distributed.nanny - WARNING - Worker process still alive after 3.199996795654297 seconds, killing\n",
      "2022-09-19 17:56:10,264 - distributed.nanny - WARNING - Worker process still alive after 3.199994659423828 seconds, killing\n",
      "\n",
      "2022-09-19 17:56:10,695 - pyscenic.cli.pyscenic - INFO - Writing results to file.\n"
     ]
    }
   ],
   "source": [
    "!pyscenic grn {EXP_FILTER_LOOM_FNAME} {HUMAN_TFS_FNAME} \\\n",
    "    -o {ADJACENCIES_FNAME} \\\n",
    "    --num_workers 8 \\\n",
    "    --method grnboost2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2-3: Regulon prediction aka cisTarget from CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-09-19 17:15:31,024 - pyscenic.cli.pyscenic - INFO - Creating modules.\n",
      "\n",
      "2022-09-19 17:15:31,028 - pyscenic.cli.pyscenic - ERROR - No columns to parse from file\n"
     ]
    }
   ],
   "source": [
    "DBS_PARAM = RANKING_DBS_FNAMES\n",
    "!pyscenic ctx {ADJACENCIES_FNAME} {DBS_PARAM} --annotations_fname {MOTIF_ANNOTATIONS_FNAME} --expression_mtx_fname {EXP_FILTER_LOOM_FNAME} --output {MOTIFS_FNAME} --num_workers 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_motifs = load_motifs(MOTIFS_FNAME)\n",
    "df_motifs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_logos(df_motifs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: Cellular enrichment aka AUCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyscenic.transform.df2regulons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pyscenic aucell {EXP_FILTER_LOOM_FNAME} {MOTIFS_FNAME} --output sample_SCENIC.loom --num_workers 8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pyscenic': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26802d61df9414c255b7e5d638781b590b227d6e5c013e77a842b62d3efd2bb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
